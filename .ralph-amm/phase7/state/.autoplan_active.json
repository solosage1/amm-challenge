{
  "schema_version": "1.0",
  "generated_at": "2026-02-11T11:17:44.931440Z",
  "iteration": 40,
  "mode": "canary",
  "execute_this_iteration": true,
  "non_regression_ok": true,
  "non_regression_reasons": [],
  "rollout_state": {
    "started_iteration": 3,
    "shadow_completed": 3,
    "canary_executed": 37,
    "rollback_triggered": false,
    "rollback_reason": null
  },
  "target_edge": 527.0,
  "reference_best_edge": 508.67,
  "selection_reason": "top_weighted_score",
  "exploration_forced": false,
  "selected_opportunity": {
    "id": "contextual_bandit_policy_search",
    "family_class": "online_learning",
    "subfamily": "exp3_adversarial_bandit",
    "subfamily_reason": "policy_select:untried|score=4.001",
    "rationale": "Use contextual bandits to choose quote aggressiveness online by flow state instead of static parameter families. [untried family bonus applied]",
    "expected_uplift": 5.35,
    "confidence": 3.45,
    "novelty": 9.5,
    "breakthrough_likelihood": 8.3,
    "untried_family": true,
    "base_weighted_score": 48.15,
    "score_bonus": 14.205,
    "weighted_score": 62.355
  },
  "policy": {
    "promotion_requires_repeats": 3,
    "family_kill_first_4_below_reference_by": 0.8,
    "family_cooldown_iterations_on_severe_failure": 4,
    "no_uplift_epsilon": 0.02,
    "no_uplift_streak_threshold": 3,
    "no_uplift_cooldown_iters": 4,
    "novelty_lookback": 6,
    "novelty_penalty": 1.0,
    "explore_quota_enabled": true,
    "explore_lookback": 4,
    "explore_min_no_uplift": 3,
    "explore_min_repeat_share": 0.6,
    "explore_repeat_classes": [
      "gating_adaptive",
      "undercut_sweep"
    ],
    "explore_target_classes": [
      "asymmetric",
      "ema_smoothing",
      "gamma_formula"
    ],
    "explore_untried_floor_enabled": true,
    "explore_stall_lookback": 10,
    "explore_stall_min_no_uplift": 7,
    "score_novelty_weight": 0.55,
    "score_breakthrough_weight": 0.6,
    "score_untried_bonus": 4.0,
    "subfamily_override": "",
    "breakthrough_tie_epsilon": 0.1,
    "severe_subfamily_failure_threshold": 2
  },
  "ranked_opportunities": [
    {
      "id": "contextual_bandit_policy_search",
      "family_class": "online_learning",
      "recommended_subfamily": "exp3_adversarial_bandit",
      "recommended_subfamily_reason": "policy_select:untried|score=4.001",
      "rationale": "Use contextual bandits to choose quote aggressiveness online by flow state instead of static parameter families. [untried family bonus applied]",
      "expected_uplift": 5.35,
      "confidence": 3.45,
      "time_to_signal": 6.5,
      "complexity": 7.2,
      "overfit_risk": 4.5,
      "novelty": 9.5,
      "breakthrough_likelihood": 8.3,
      "untried_family": true,
      "base_weighted_score": 48.15,
      "score_bonus": 14.205,
      "weighted_score": 62.355
    },
    {
      "id": "distributionally_robust_control_search",
      "family_class": "adversarial_robustness",
      "recommended_subfamily": "worst_case_regime_mix",
      "recommended_subfamily_reason": "policy_select:untried|score=4.001",
      "rationale": "Optimize against worst-case regime mixtures (CVaR/ambiguity sets) to avoid collapse under adversarial flow. [untried family bonus applied]",
      "expected_uplift": 5.55,
      "confidence": 3.25,
      "time_to_signal": 5.5,
      "complexity": 7.8,
      "overfit_risk": 3.0,
      "novelty": 9.0,
      "breakthrough_likelihood": 8.0,
      "untried_family": true,
      "base_weighted_score": 48.5,
      "score_bonus": 13.75,
      "weighted_score": 62.25
    },
    {
      "id": "inventory_hjb_control_search",
      "family_class": "optimal_control",
      "recommended_subfamily": "hjb_discrete_inventory",
      "recommended_subfamily_reason": "policy_select:untried|score=4.000",
      "rationale": "Introduce inventory-aware optimal control (HJB/Avellaneda-Stoikov style) so spread/undercut adapts to risk state, not just mispricing. [untried family bonus applied]",
      "expected_uplift": 5.85,
      "confidence": 3.15,
      "time_to_signal": 5.5,
      "complexity": 8.0,
      "overfit_risk": 4.2,
      "novelty": 9.3,
      "breakthrough_likelihood": 8.4,
      "untried_family": true,
      "base_weighted_score": 47.3,
      "score_bonus": 14.155,
      "weighted_score": 61.455
    },
    {
      "id": "queue_microprice_impact_search",
      "family_class": "microstructure",
      "recommended_subfamily": "microprice_imbalance",
      "recommended_subfamily_reason": "policy_select:untried|score=4.001",
      "rationale": "Quote off queue/microprice and short-horizon impact estimates to capture microstructure alpha orthogonal to undercut tuning. [untried family bonus applied]",
      "expected_uplift": 5.25,
      "confidence": 3.35,
      "time_to_signal": 6.0,
      "complexity": 7.3,
      "overfit_risk": 4.1,
      "novelty": 8.8,
      "breakthrough_likelihood": 7.9,
      "untried_family": true,
      "base_weighted_score": 47.3,
      "score_bonus": 13.58,
      "weighted_score": 60.88
    },
    {
      "id": "bayesian_optimization_meta_search",
      "family_class": "bayesian_optimization",
      "recommended_subfamily": "turbo_trust_region",
      "recommended_subfamily_reason": "policy_select:untried|score=4.001",
      "rationale": "Use surrogate-driven search (GP/TuRBO/multi-fidelity) to jump across non-local strategy manifolds instead of linear sweeps. [untried family bonus applied]",
      "expected_uplift": 5.05,
      "confidence": 3.35,
      "time_to_signal": 6.0,
      "complexity": 7.4,
      "overfit_risk": 3.8,
      "novelty": 8.6,
      "breakthrough_likelihood": 7.6,
      "untried_family": true,
      "base_weighted_score": 46.95,
      "score_bonus": 13.29,
      "weighted_score": 60.24
    },
    {
      "id": "adversarial_regime_sim_search",
      "family_class": "adversarial_robustness",
      "recommended_subfamily": "stress_regime_mixture",
      "recommended_subfamily_reason": "policy_select:untried|score=4.001",
      "rationale": "Stress-test with adversarial regime replay/change-point detectors to learn policies that survive worst-case transitions. [untried family bonus applied]",
      "expected_uplift": 5.15,
      "confidence": 3.05,
      "time_to_signal": 5.0,
      "complexity": 7.9,
      "overfit_risk": 2.8,
      "novelty": 9.0,
      "breakthrough_likelihood": 8.0,
      "untried_family": true,
      "base_weighted_score": 46.05,
      "score_bonus": 13.75,
      "weighted_score": 59.8
    },
    {
      "id": "asymmetric_bid_ask_search",
      "family_class": "asymmetric",
      "recommended_subfamily": "bid_ask_asymmetry",
      "recommended_subfamily_reason": "policy_select:untried|score=4.000",
      "rationale": "Directional asymmetry can create edge where symmetric undercut sweeps plateau. [untried family bonus applied]",
      "expected_uplift": 3.25,
      "confidence": 3.95,
      "time_to_signal": 7.5,
      "complexity": 6.0,
      "overfit_risk": 4.2,
      "novelty": 8.4,
      "breakthrough_likelihood": 7.5,
      "untried_family": true,
      "base_weighted_score": 45.2,
      "score_bonus": 13.12,
      "weighted_score": 58.32
    },
    {
      "id": "gamma_formula_search",
      "family_class": "gamma_formula",
      "recommended_subfamily": "gamma_transform",
      "recommended_subfamily_reason": "policy_select:untried|score=4.001",
      "rationale": "Local sweep stagnation suggests changing competitive/protective gamma math itself. [untried family bonus applied]",
      "expected_uplift": 3.45,
      "confidence": 3.85,
      "time_to_signal": 6.5,
      "complexity": 7.0,
      "overfit_risk": 4.0,
      "novelty": 7.6,
      "breakthrough_likelihood": 7.8,
      "untried_family": true,
      "base_weighted_score": 43.45,
      "score_bonus": 12.86,
      "weighted_score": 56.31
    },
    {
      "id": "robustness_repair_search",
      "family_class": "ema_smoothing",
      "recommended_subfamily": "spread_stabilizer",
      "recommended_subfamily_reason": "policy_select:untried|score=4.001",
      "rationale": "Spread instability indicates robust-score improvements may unlock reliable gains. [untried family bonus applied]",
      "expected_uplift": 2.75,
      "confidence": 3.75,
      "time_to_signal": 7.0,
      "complexity": 5.0,
      "overfit_risk": 3.0,
      "novelty": 4.6,
      "breakthrough_likelihood": 5.2,
      "untried_family": true,
      "base_weighted_score": 45.0,
      "score_bonus": 9.65,
      "weighted_score": 54.65
    },
    {
      "id": "parallel_parameter_beam",
      "family_class": "gating_adaptive",
      "recommended_subfamily": "parameter_beam",
      "recommended_subfamily_reason": "policy_select:probe_confirm|score=0.350",
      "rationale": "If sweep throughput is bottlenecked, parallel beams can improve search efficiency.",
      "expected_uplift": 1.75,
      "confidence": 6.0,
      "time_to_signal": 9.0,
      "complexity": 4.0,
      "overfit_risk": 6.0,
      "novelty": 3.0,
      "breakthrough_likelihood": 3.8,
      "untried_family": false,
      "base_weighted_score": 46.625,
      "score_bonus": 3.93,
      "weighted_score": 50.555
    },
    {
      "id": "adaptive_undercut_search",
      "family_class": "undercut_sweep",
      "recommended_subfamily": "step_aware_undercut",
      "recommended_subfamily_reason": "policy_select:probe_confirm|score=1.350",
      "rationale": "Undercut signal is strong; prefer lightweight regime-aware undercut before heavy state-machine logic. [novelty penalty: 2.00; 2/2 recent attempts had no uplift]",
      "expected_uplift": 3.05,
      "confidence": 3.25,
      "time_to_signal": 8.0,
      "complexity": 3.0,
      "overfit_risk": 4.0,
      "novelty": 2.5,
      "breakthrough_likelihood": 3.2,
      "untried_family": false,
      "base_weighted_score": 46.8,
      "score_bonus": 3.295,
      "weighted_score": 50.095
    },
    {
      "id": "ema_smoothing_search",
      "family_class": "ema_smoothing",
      "recommended_subfamily": "ema_smoothing",
      "recommended_subfamily_reason": "all_subfamilies_cooldown_select_best:recent_no_uplift,cooldown_until_40,probe_confirm",
      "rationale": "Fair-value smoothing/jump-limiter dynamics are likely under-tuned near the local optimum. [novelty penalty: 2.00; 2/2 recent attempts had no uplift]",
      "expected_uplift": 2.3,
      "confidence": 2.3,
      "time_to_signal": 7.0,
      "complexity": 5.0,
      "overfit_risk": 3.5,
      "novelty": 4.0,
      "breakthrough_likelihood": 4.8,
      "untried_family": false,
      "base_weighted_score": 39.05,
      "score_bonus": 5.08,
      "weighted_score": 44.13
    },
    {
      "id": "regime_state_transition_search",
      "family_class": "gating_adaptive",
      "recommended_subfamily": "heavy_state_machine",
      "recommended_subfamily_reason": "policy_select:untried|score=4.000",
      "rationale": "Plateau/brittleness suggest structure-level transition logic is under-optimized. [cooldown active: 4 iteration(s), until 43]",
      "expected_uplift": 1.75,
      "confidence": 0.25,
      "time_to_signal": 6.0,
      "complexity": 6.0,
      "overfit_risk": 5.0,
      "novelty": 3.0,
      "breakthrough_likelihood": 3.8,
      "untried_family": false,
      "base_weighted_score": 27.25,
      "score_bonus": 3.93,
      "weighted_score": 31.18
    }
  ],
  "search_plan": {
    "frozen_core": [
      "canonical 1000-sim validation",
      "existing champion safety clamps",
      "effective-score fallback guardrails"
    ],
    "mutation_dimensions": [
      "arm definitions for quote aggressiveness regimes",
      "context features from mispricing/flow burst/inventory proxy",
      "policy update rule (Thompson, UCB, EXP3)",
      "exploration temperature and regret cap"
    ],
    "run_budget": {
      "variants": 10,
      "parallel_workers": 4,
      "authoritative_sims": 1000
    },
    "promotion_criteria": {
      "median_delta_vs_reference": 0.25,
      "required_repeats": 3,
      "max_spread": 55.0
    },
    "kill_criteria": {
      "abort_family_if_first_4_below_reference_by": 0.8,
      "abort_family_if_batch_best_below_reference_by": 0.5,
      "first_run_delta_below": -1.2
    },
    "falsification_test": "If regret-aware policy variants do not beat static control after 10 variants, reject online policy hypothesis.",
    "fallback_strategy": {
      "action": "retain_champion",
      "strategy_edge": 508.67
    },
    "subfamily_focus": "exp3_adversarial_bandit",
    "subfamily_focus_reason": "policy_select:untried|score=4.001"
  }
}